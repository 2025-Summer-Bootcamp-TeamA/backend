import logging
from typing import Optional
from .script_service import ScriptAnalyzer, AnalysisResult
from .gemini_service import GeminiService

logger = logging.getLogger(__name__)


class HybridAnalyzer:
    """
    í•˜ì´ë¸Œë¦¬ë“œ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°
    
    ì „ëµ:
    1ë‹¨ê³„: ScriptAnalyzerë¡œ ë¹ ë¥¸ ê·œì¹™ ê¸°ë°˜ ë¶„ì„ (90% ì¼€ì´ìŠ¤)
    2ë‹¨ê³„: ì‹ ë¢°ë„ ë‚®ìœ¼ë©´ GeminiServiceë¡œ AI ë¶„ì„ (10% ì¼€ì´ìŠ¤)
    
    ì¥ì :
    - ë¹ ë¥¸ ì²˜ë¦¬ (ëŒ€ë¶€ë¶„ ê·œì¹™ ê¸°ë°˜)
    - ë†’ì€ ì •í™•ë„ (ì• ë§¤í•œ ì¼€ì´ìŠ¤ëŠ” AI)
    - ë¹„ìš© íš¨ìœ¨ì  (í•„ìš”ì‹œì—ë§Œ AI í˜¸ì¶œ)
    """
    
    def __init__(self, gemini_credentials_path: Optional[str] = None, 
                 confidence_threshold: float = 0.75):
        """
        í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            gemini_credentials_path: Gemini ì„œë¹„ìŠ¤ ê³„ì • íŒŒì¼ ê²½ë¡œ
            confidence_threshold: AI ì‚¬ìš© ê¸°ì¤€ ì‹ ë¢°ë„ (ì´í•˜ë©´ AI ì‚¬ìš©)
        """
        # 1ë‹¨ê³„: ê·œì¹™ ê¸°ë°˜ ë¶„ì„ê¸° (í•­ìƒ ì‚¬ìš©)
        self.script_analyzer = ScriptAnalyzer()
        
        # 2ë‹¨ê³„: AI ë¶„ì„ê¸° (ì¡°ê±´ë¶€ ì‚¬ìš©)
        self.gemini_service = None
        self.gemini_available = False
        
        try:
            self.gemini_service = GeminiService(gemini_credentials_path)
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            if self.gemini_service.test_connection():
                self.gemini_available = True
                logger.info("âœ… Gemini AI ì„œë¹„ìŠ¤ ì—°ê²° ì„±ê³µ - í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ í™œì„±í™”")
            else:
                logger.warning("âš ï¸ Gemini AI ì—°ê²° ì‹¤íŒ¨ - ê·œì¹™ ê¸°ë°˜ ëª¨ë“œë§Œ ì‚¬ìš©")
        except Exception as e:
            logger.warning(f"âš ï¸ Gemini AI ì´ˆê¸°í™” ì‹¤íŒ¨: {e} - ê·œì¹™ ê¸°ë°˜ ëª¨ë“œë§Œ ì‚¬ìš©")
        
        self.confidence_threshold = confidence_threshold
        
        # í†µê³„ ì¶”ì 
        self.stats = {
            "total_analyzed": 0,
            "rule_based_only": 0,
            "ai_assisted": 0,
            "ai_success": 0,
            "ai_fallback": 0
        }
    
    def analyze_text(self, text: str) -> AnalysisResult:
        """
        í•˜ì´ë¸Œë¦¬ë“œ í…ìŠ¤íŠ¸ ë¶„ì„
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            AnalysisResult: ë¶„ì„ ê²°ê³¼ (source ë©”íƒ€ë°ì´í„°ë¡œ ì–´ë–¤ ë°©ì‹ ì‚¬ìš©í–ˆëŠ”ì§€ í‘œì‹œ)
        """
        self.stats["total_analyzed"] += 1
        
        if not text or not text.strip():
            return AnalysisResult(
                text_type=self.script_analyzer.analyze_text("").text_type,
                confidence=1.0,
                is_description=False,
                reasoning="ë¹ˆ í…ìŠ¤íŠ¸",
                metadata={"source": "rule_based", "stage": "input_validation"}
            )
        
        # ğŸ”¥ 1ë‹¨ê³„: ê·œì¹™ ê¸°ë°˜ ë¶„ì„ (ë¹ ë¥´ê³  ë¬´ë£Œ)
        rule_result = self.script_analyzer.analyze_text(text)
        
        # ì‹ ë¢°ë„ê°€ ë†’ìœ¼ë©´ ë°”ë¡œ ë°˜í™˜ (90% ì¼€ì´ìŠ¤)
        if rule_result.confidence >= self.confidence_threshold:
            self.stats["rule_based_only"] += 1
            
            # ë©”íƒ€ë°ì´í„°ì— ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€
            if not rule_result.metadata:
                rule_result.metadata = {}
            rule_result.metadata.update({
                "source": "rule_based",
                "stage": "confident_result",
                "original_confidence": rule_result.confidence
            })
            
            logger.debug(f"ê·œì¹™ ê¸°ë°˜ ì™„ë£Œ (ì‹ ë¢°ë„: {rule_result.confidence:.2f}): {text[:50]}...")
            return rule_result
        
        # ğŸ¤– 2ë‹¨ê³„: AI ë¶„ì„ (ì• ë§¤í•œ ê²½ìš°ë§Œ, 10% ì¼€ì´ìŠ¤)
        if self.gemini_available:
            return self._ai_analysis(text, rule_result)
        else:
            # AI ì‚¬ìš© ë¶ˆê°€ì‹œ ê·œì¹™ ê¸°ë°˜ ê²°ê³¼ ë°˜í™˜
            self.stats["ai_fallback"] += 1
            
            if not rule_result.metadata:
                rule_result.metadata = {}
            rule_result.metadata.update({
                "source": "rule_based_fallback",
                "stage": "ai_unavailable",
                "original_confidence": rule_result.confidence,
                "reason": "AI ì„œë¹„ìŠ¤ ì‚¬ìš© ë¶ˆê°€"
            })
            
            logger.debug(f"AI ë¶ˆê°€ - ê·œì¹™ ê¸°ë°˜ fallback: {text[:50]}...")
            return rule_result
    
    def _ai_analysis(self, text: str, rule_result: AnalysisResult) -> AnalysisResult:
        """AI ë¶„ì„ ìˆ˜í–‰"""
        self.stats["ai_assisted"] += 1
        
        try:
            # Geminië¡œ AI ë¶„ì„
            ai_is_description = self.gemini_service.is_description(text)
            self.stats["ai_success"] += 1
            
            # AI ê²°ê³¼ë¥¼ AnalysisResult í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            ai_result = AnalysisResult(
                text_type=rule_result.text_type,  # í…ìŠ¤íŠ¸ ìœ í˜•ì€ ê·œì¹™ ê¸°ë°˜ ê²°ê³¼ ì‚¬ìš©
                confidence=0.95,  # AI ê²°ê³¼ëŠ” ë†’ì€ ì‹ ë¢°ë„
                is_description=ai_is_description,
                reasoning=f"í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„: ê·œì¹™ ê¸°ë°˜ ì‹ ë¢°ë„ {rule_result.confidence:.2f} â†’ AI ë¶„ì„ ì ìš©",
                metadata={
                    "source": "hybrid_ai",
                    "stage": "ai_analysis",
                    "rule_confidence": rule_result.confidence,
                    "rule_result": rule_result.is_description,
                    "ai_result": ai_is_description,
                    "text_length": len(text)
                }
            )
            
            logger.debug(f"AI ë¶„ì„ ì™„ë£Œ (ê·œì¹™: {rule_result.is_description} â†’ AI: {ai_is_description}): {text[:50]}...")
            return ai_result
            
        except Exception as e:
            # AI ì‹¤íŒ¨ì‹œ ê·œì¹™ ê¸°ë°˜ ê²°ê³¼ ì‚¬ìš©
            self.stats["ai_fallback"] += 1
            logger.warning(f"AI ë¶„ì„ ì‹¤íŒ¨, ê·œì¹™ ê¸°ë°˜ ì‚¬ìš©: {e}")
            
            if not rule_result.metadata:
                rule_result.metadata = {}
            rule_result.metadata.update({
                "source": "rule_based_fallback",
                "stage": "ai_error",
                "original_confidence": rule_result.confidence,
                "error": str(e)
            })
            
            return rule_result
    
    def is_description(self, text: str) -> bool:
        """
        ê°„ë‹¨í•œ ì„¤ëª… ì—¬ë¶€ íŒë‹¨ (booleanë§Œ ë°˜í™˜)
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            bool: ì„¤ëª…ì´ë©´ True, ì•„ë‹ˆë©´ False
        """
        result = self.analyze_text(text)
        return result.is_description
    
    def get_analysis_stats(self) -> dict:
        """
        ë¶„ì„ í†µê³„ ë°˜í™˜
        
        Returns:
            dict: ì‚¬ìš© íŒ¨í„´ í†µê³„
        """
        total = self.stats["total_analyzed"]
        if total == 0:
            return self.stats
        
        return {
            **self.stats,
            "rule_based_percentage": (self.stats["rule_based_only"] / total) * 100,
            "ai_usage_percentage": (self.stats["ai_assisted"] / total) * 100,
            "ai_success_rate": (self.stats["ai_success"] / max(self.stats["ai_assisted"], 1)) * 100,
        }
    

